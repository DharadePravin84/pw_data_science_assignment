{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
        "\n",
        "Web Scraping: The process of automatically extracting data from websites using software.\n",
        "\n",
        "Why is it Used?\n",
        "- To collect large amounts of data for analysis.\n",
        "- To gather data that is not available through an API.\n",
        "- To automate data extraction processes.\n",
        "\n",
        "Three Areas Where Web Scraping is Used:\n",
        "1. Market Research: Collecting product prices and reviews.\n",
        "2. News Aggregation: Compiling news articles from various sources.\n",
        "3. Social Media Analysis: Extracting user posts and comments for sentiment analysis.\n",
        "\n",
        "Q2. What are the different methods used for Web Scraping?\n",
        "\n",
        "1. HTML Parsing: Using libraries like Beautiful Soup to parse and extract data from HTML documents.\n",
        "2. DOM Parsing: Utilizing web browsers or tools like Selenium to navigate and extract data from web pages.\n",
        "3. XPath: Using XML Path Language to navigate and extract information from XML documents.\n",
        "4. API Scraping: Accessing data through a website's public or private API.\n",
        "5. Regular Expressions: Using regex patterns to identify and extract data.\n",
        "\n",
        "\n",
        "Q3. What is Beautiful Soup? Why is it used?\n",
        "\n",
        "Beautiful Soup: A Python library for parsing HTML and XML documents.\n",
        "\n",
        "Why is it Used?\n",
        "\n",
        "- To navigate the parse tree and search for elements by tags, attributes, and text.\n",
        "- To clean and format the extracted data.\n",
        "- To simplify the process of web scraping by providing easy-to-use methods for extracting data.\n",
        "\n",
        "Q4. Why is flask used in this Web Scraping project?\n",
        "\n",
        "Flask: A lightweight Python web framework.\n",
        "\n",
        "Why is it Used?\n",
        "\n",
        "- To create a web server that can handle HTTP requests and serve scraped data.\n",
        "- To provide an interface for users to interact with the web scraping functionality.\n",
        "- To integrate and run the web scraping scripts as part of a web application.\n",
        "\n",
        "Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
        "\n",
        "1. Amazon EC2 (Elastic Compute Cloud):\n",
        " - Use: To host and run the web scraping application and server.\n",
        "\n",
        "2. Amazon S3 (Simple Storage Service):\n",
        " - Use: To store the scraped data and any related files.\n",
        "\n",
        "3. Amazon RDS (Relational Database Service):\n",
        " - Use: To store and manage structured data collected from web scraping.\n",
        "\n",
        "4. AWS Lambda:\n",
        " - Use: To run serverless functions that perform scraping tasks on a schedule.\n",
        "\n",
        "5. Amazon CloudWatch:\n",
        " - Use: To monitor the performance and logs of the web scraping application and resources."
      ],
      "metadata": {
        "id": "7EXJNhqh6UE3"
      }
    }
  ]
}
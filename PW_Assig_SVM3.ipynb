{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# Load the dataset\n",
        "data_path = '/content/Bengaluru_House_Data.csv'\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Handle missing values\n",
        "df = df.dropna(subset=['location', 'size', 'total_sqft', 'bath', 'balcony', 'price'])\n",
        "\n",
        "# Split the 'size' column into 'bedrooms'\n",
        "df['bedrooms'] = df['size'].apply(lambda x: int(x.split(' ')[0]))\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df = df.drop(columns=['area_type', 'availability', 'society', 'size'])\n",
        "\n",
        "# Convert 'total_sqft' to numeric (assuming it is in the format 'number - number')\n",
        "def convert_sqft_to_num(x):\n",
        "    tokens = x.split('-')\n",
        "    if len(tokens) == 2:\n",
        "        return (float(tokens[0]) + float(tokens[1])) / 2\n",
        "    try:\n",
        "        return float(x)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "df['total_sqft'] = df['total_sqft'].apply(convert_sqft_to_num)\n",
        "\n",
        "# Drop rows with invalid 'total_sqft'\n",
        "df = df.dropna(subset=['total_sqft'])\n",
        "\n",
        "# Split the dataset into features and target variable\n",
        "X = df.drop(columns=['price'])\n",
        "y = df['price']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Preprocess the data\n",
        "numeric_features = ['total_sqft', 'bath', 'balcony', 'bedrooms']\n",
        "categorical_features = ['location']\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Create a pipeline that first preprocesses the data and then trains the model\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', SVR())\n",
        "])\n",
        "\n",
        "# Tuning the hyperparameters of the SVR using GridSearchCV\n",
        "param_grid = {\n",
        "    'regressor__C': [0.1, 1, 10, 100],\n",
        "    'regressor__epsilon': [0.1, 0.2, 0.5, 1],\n",
        "    'regressor__kernel': ['linear', 'poly', 'rbf'],\n",
        "    'regressor__gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best score: {grid_search.best_score_}\")\n",
        "\n",
        "# Train the tuned classifier on the entire dataset\n",
        "best_model = grid_search.best_estimator_\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the testing set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"MAE: {mae}\")\n",
        "print(f\"MSE: {mse}\")\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "# Save the trained classifier to a file for future use\n",
        "joblib_file = \"svr_model.pkl\"\n",
        "joblib.dump(best_model, joblib_file)\n"
      ],
      "metadata": {
        "id": "ut7l9x_fj_IK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SfFLBm6TkFdx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmmrkYeWpHLj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "topic : understanding pooling and padding in cnn.\n",
        "1. Describe the purpose and benifits of pooling in CNN.\n",
        "- Ans:Purpose and Benefits of Pooling:\n",
        "\n",
        "Pooling layers in convolutional neural networks (CNNs) serve two main purposes: reducing the spatial dimensions (downsampling) and extracting dominant features.\n",
        "By reducing the spatial dimensions, pooling helps in controlling overfitting by reducing the number of parameters and computational complexity.\n",
        "Pooling also helps in achieving translation invariance, making the network more robust to slight variations in the input.\n",
        "\n",
        "2. Explain the difference between min pooling and max pooling.\n",
        "- Ans: Difference between Min Pooling and Max Pooling:\n",
        "\n",
        "Max pooling takes the maximum value from the input window, preserving only the most active features.\n",
        "Min pooling, on the other hand, takes the minimum value from the input window.\n",
        "Max pooling is more commonly used as it helps in preserving the most important features while discarding irrelevant ones.\n",
        "\n",
        "3. Discuss the concept of padding in CNN and its significance.\n",
        "-Ans: Concept of Padding in CNN and Its Significance:\n",
        "\n",
        "Padding is the process of adding extra pixels around the input image, allowing the convolution operation to be applied to border pixels.\n",
        "Padding is significant because it helps in preserving spatial dimensions and information at the borders of the image.\n",
        "It also helps in controlling the spatial size of the output feature maps after convolution and ensures that the output has the desired spatial dimensions.\n",
        "\n",
        "4. Compare and contrast zero-padding and valid-padding in terms of their effects on the output feature map size.\n",
        "- Ans: Comparison between Zero-padding and Valid-padding:\n",
        "\n",
        "Zero-padding adds zero-value pixels around the input image.\n",
        "Valid-padding does not add any extra pixels.\n",
        "Zero-padding preserves the spatial dimensions of the input image, while valid-padding reduces the spatial dimensions based on the size of the filter/kernel used in convolution.\n",
        "Zero-padding is commonly used when the spatial dimensions need to be preserved, especially in deep networks where multiple convolutional layers are stacked.\n",
        "\n",
        "TOPIC: Exploring LeNet\n",
        "1. Provide a brif overview of LeNet-5 architecture.\n",
        "- Ans: Overview of LeNet-5 Architecture:\n",
        "\n",
        "LeNet-5 is a pioneering convolutional neural network designed by Yann LeCun et al. for handwritten digit recognition.\n",
        "It consists of seven layers, including three convolutional layers and two fully connected layers.\n",
        "\n",
        "2. Desccire the key components of LeNet-5 and their respective purposes.\n",
        "- Ans: Key Components of LeNet-5:\n",
        "\n",
        "Convolutional layers with sigmoid activation functions.\n",
        "Average pooling layers.\n",
        "Fully connected layers.\n",
        "Tanh or sigmoid activation functions in fully connected layers.\n",
        "LeNet-5 uses a combination of convolution, pooling, and fully connected layers to extract features and classify images.\n",
        "\n",
        "3.Discuss the advantages and limitations of LeNet-5 in the contex of image classification tasks.\n",
        "- Ans: Advantages and Limitations of LeNet-5:\n",
        "\n",
        "Advantages: Efficient in recognizing handwritten digits, relatively simple architecture, paved the way for modern CNNs.\n",
        "Limitations: Limited capacity for handling more complex datasets, such as large-scale image classification tasks.\n",
        "\n",
        "4. Implement LeNet-5 using a deep learning framework of your choice(eg. TensoreFlow, PyTorch)\n",
        "and train it on a publicly available dataset(eg.MNIST).Evaluate its performance and provide insights.\n",
        "\n"
      ],
      "metadata": {
        "id": "UHc22V-UpHlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time\n",
        "\n",
        "# Load MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Define the LeNet-5 architecture\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(6, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(16, (5, 5), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(120, activation='relu'))\n",
        "model.add(layers.Dense(84, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "start_time = time.time()\n",
        "history = model.fit(train_images, train_labels, epochs=5, batch_size=64, validation_data=(test_images, test_labels))\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print(\"Test Accuracy:\", test_acc)\n",
        "print(\"Training Time:\", training_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKD4RjwWslDy",
        "outputId": "b090910a-bfe0-4a8e-cf98-a9036455aa80"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 19s 19ms/step - loss: 0.2327 - accuracy: 0.9299 - val_loss: 0.0703 - val_accuracy: 0.9779\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 15s 16ms/step - loss: 0.0670 - accuracy: 0.9796 - val_loss: 0.0594 - val_accuracy: 0.9810\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 15s 16ms/step - loss: 0.0475 - accuracy: 0.9854 - val_loss: 0.0410 - val_accuracy: 0.9873\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 15s 16ms/step - loss: 0.0372 - accuracy: 0.9883 - val_loss: 0.0417 - val_accuracy: 0.9871\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 15s 16ms/step - loss: 0.0307 - accuracy: 0.9903 - val_loss: 0.0360 - val_accuracy: 0.9876\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0360 - accuracy: 0.9876\n",
            "Test Accuracy: 0.9876000285148621\n",
            "Training Time: 83.33704566955566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TOPIC: Analyzing AlexNet\n",
        "1. Present an overview of the AlexNet architecture.\n",
        "- Ans: Overview of AlexNet Architecture:\n",
        "\n",
        "AlexNet is a deep convolutional neural network designed by Alex Krizhevsky et al. that achieved groundbreaking performance in the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2012.\n",
        "It consists of eight layers, including five convolutional layers and three fully connected layers.\n",
        "\n",
        "2. Explain the architectural innovations introduced in AlexNet that contributed to its breakthrough performance.\n",
        "- Ans: Architectural Innovations in AlexNet:\n",
        "\n",
        "Use of ReLU activation functions.\n",
        "Utilization of dropout regularization.\n",
        "Data augmentation techniques.\n",
        "Utilization of GPU acceleration for training.\n",
        "\n",
        "\n",
        "3. Discuss the role of convolution layers, pooling layers, and fully connected layers in AlexNet.\n",
        "- Ans:\n",
        "Role of Convolution Layers, Pooling Layers, and Fully Connected Layers:\n",
        "\n",
        "Convolution layers: Extract hierarchical features from input images.\n",
        "Pooling layers: Downsample feature maps and introduce translation invariance.\n",
        "Fully connected layers: Classify extracted features into different categories.\n",
        "\n",
        "4. Implement AlexNet using a deep learning framework of your choice and evatuate its performance on a dataset of your choice."
      ],
      "metadata": {
        "id": "lnZyTpcBswq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Define the AlexNet architecture\n",
        "model = models.Sequential()\n",
        "model.add(layers.experimental.preprocessing.Resizing(224, 224, interpolation=\"bilinear\", input_shape=(32, 32, 3)))\n",
        "model.add(layers.Conv2D(96, 11, strides=4, padding='same'))\n",
        "model.add(layers.Lambda(tf.nn.local_response_normalization))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.MaxPooling2D(3, strides=2))\n",
        "model.add(layers.Conv2D(256, 5, strides=4, padding='same'))\n",
        "model.add(layers.Lambda(tf.nn.local_response_normalization))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.MaxPooling2D(3, strides=2))\n",
        "model.add(layers.Conv2D(384, 3, strides=4, padding='same'))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.Conv2D(384, 3, strides=4, padding='same'))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.Conv2D(256, 3, strides=4, padding='same'))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(4096, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(4096, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "start_time = time.time()\n",
        "history = model.fit(train_images, train_labels, epochs=10, batch_size=128, validation_data=(test_images, test_labels))\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print(\"Test Accuracy:\", test_acc)\n",
        "print(\"Training Time:\", training_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LAfO1KIumer",
        "outputId": "f9fce978-12f9-4eb5-bea2-7fdf21d36da8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - 1185s 3s/step - loss: 2.3032 - accuracy: 0.0999 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 2/10\n",
            " 59/391 [===>..........................] - ETA: 16:20 - loss: 2.3026 - accuracy: 0.0985"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CtFdBLl7ztt_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
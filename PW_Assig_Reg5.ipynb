{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is Elastic Net Regression and how does it differ from other regression techniques?\n",
        "\n",
        "Elastic Net Regression:\n",
        "\n",
        "Definition: Elastic Net Regression combines L1 and L2 regularization (i.e., it combines the penalties of Lasso and Ridge regression). It is particularly useful when dealing with highly correlated predictors.\n",
        "\n",
        "Differences from Other Regression Techniques:\n",
        "\n",
        "OLS Regression: No regularization, purely minimizes the sum of squared residuals.\n",
        "\n",
        "Ridge Regression: Adds L2 regularization, which shrinks coefficients but does not set any to zero.\n",
        "\n",
        "Lasso Regression: Adds L1 regularization, which can shrink some coefficients to zero, effectively performing feature selection.\n",
        "\n",
        "Elastic Net Regression: Combines both L1 and L2 regularization, providing a balance that can handle correlated features better than Lasso alone.\n",
        "\n",
        "\n",
        "Q2. How do you choose the optimal values of the regularization parameters for Elastic Net Regression?\n",
        "Optimal values for the regularization parameters λ1(L1 ratio) and λ2(alpha) can be selected using cross-validation:\n",
        "\n",
        "Cross-Validation: Split the data into training and validation sets multiple times, train the model on the training sets, and evaluate it on the validation sets for different combinations of λ1 and λ2​ . The combination that minimizes the cross-validated error is chosen."
      ],
      "metadata": {
        "id": "3LWOstFVtDuc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0_oA9ACs5fP",
        "outputId": "0bbbbe68-fecf-4dd4-8767-898edd5e4585"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal alpha: 0.1\n",
            "Optimal l1_ratio: 0.1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import ElasticNetCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generating example data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 10)\n",
        "y = np.dot(X, np.random.rand(10)) + np.random.normal(0, 0.1, 100)\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a range of alpha and l1_ratio values\n",
        "alphas = [0.1, 1.0, 10.0]\n",
        "l1_ratios = [0.1, 0.5, 0.9]\n",
        "\n",
        "# Use ElasticNetCV to find the optimal alpha and l1_ratio\n",
        "elastic_net_cv = ElasticNetCV(alphas=alphas, l1_ratio=l1_ratios, cv=5)\n",
        "elastic_net_cv.fit(X_train, y_train)\n",
        "\n",
        "# Optimal alpha and l1_ratio\n",
        "optimal_alpha = elastic_net_cv.alpha_\n",
        "optimal_l1_ratio = elastic_net_cv.l1_ratio_\n",
        "print(f\"Optimal alpha: {optimal_alpha}\")\n",
        "print(f\"Optimal l1_ratio: {optimal_l1_ratio}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. What are the advantages and disadvantages of Elastic Net Regression?\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Feature Selection: Like Lasso, it can set some coefficients to zero, effectively performing feature selection.\n",
        "\n",
        "Handles Multicollinearity: Better than Lasso when dealing with highly correlated predictors.\n",
        "\n",
        "Flexibility: Balances L1 and L2 regularization, providing more flexibility than either Ridge or Lasso alone.\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "Computational Complexity: More computationally intensive than Ridge or Lasso alone due to the need to optimize two regularization parameters.\n",
        "\n",
        "Interpretability: The presence of both L1 and L2 penalties can make the interpretation of coefficients more complex.\n",
        "\n",
        "\n",
        "Q4. What are some common use cases for Elastic Net Regression?\n",
        "\n",
        "Common Use Cases:\n",
        "\n",
        "High-Dimensional Data: Situations with a large number of predictors, especially when predictors are correlated.\n",
        "\n",
        "Feature Selection: When feature selection is needed but Ridge or Lasso alone are not sufficient.\n",
        "\n",
        "Genomics and Bioinformatics: Often used in genetics to handle correlated gene expression data.\n",
        "\n",
        "Economics and Finance: Applied in models with many economic indicators that may be correlated.\n",
        "\n",
        "\n",
        "Q5. How do you interpret the coefficients in Elastic Net Regression?\n",
        "\n",
        "The coefficients in Elastic Net Regression can be interpreted similarly to other linear models, with the understanding that:\n",
        "\n",
        "Shrinkage: Coefficients are shrunk due to regularization, meaning their magnitudes are reduced.\n",
        "\n",
        "Zero Coefficients: Some coefficients may be exactly zero if the L1 penalty dominates, indicating that those features are not important predictors in the model.\n",
        "\n",
        "Relative Importance: The magnitude of non-zero coefficients indicates the relative importance of those features.\n",
        "\n",
        "\n",
        "Q6. How do you handle missing values when using Elastic Net Regression?\n",
        "\n",
        "Handling missing values typically involves imputation before fitting the model:\n",
        "\n",
        "Imputation: Replace missing values with a statistical measure (mean, median, mode) or use more sophisticated methods (K-Nearest Neighbors imputation, iterative imputation)."
      ],
      "metadata": {
        "id": "_nEsBqM6uLGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Impute missing values with mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test)\n"
      ],
      "metadata": {
        "id": "qRdcqvPtuE_5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. How do you use Elastic Net Regression for feature selection?\n",
        "\n",
        "Elastic Net Regression performs feature selection by shrinking some coefficients to zero due to the L1 penalty. Features with non-zero coefficients are considered selected.\n",
        "\n",
        "Procedure:\n",
        "\n",
        "Fit the Elastic Net model.\n",
        "\n",
        "Identify features with non-zero coefficients."
      ],
      "metadata": {
        "id": "3R4JIbaPumbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generating example data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 10)\n",
        "y = np.dot(X, np.random.rand(10)) + np.random.normal(0, 0.1, 100)\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a range of alpha and l1_ratio values\n",
        "alphas = [0.1, 1.0, 10.0]\n",
        "l1_ratios = [0.1, 0.5, 0.9]\n",
        "\n",
        "# Use ElasticNetCV to find the optimal alpha and l1_ratio\n",
        "elastic_net_cv = ElasticNetCV(alphas=alphas, l1_ratio=l1_ratios, cv=5)\n",
        "elastic_net_cv.fit(X_train, y_train)\n",
        "\n",
        "# Optimal alpha and l1_ratio\n",
        "optimal_alpha = elastic_net_cv.alpha_\n",
        "optimal_l1_ratio = elastic_net_cv.l1_ratio_\n",
        "print(f\"Optimal alpha: {optimal_alpha}\")\n",
        "print(f\"Optimal l1_ratio: {optimal_l1_ratio}\")\n",
        "\n",
        "# Train the ElasticNet model with the optimal parameters\n",
        "elastic_net = ElasticNet(alpha=optimal_alpha, l1_ratio=optimal_l1_ratio)\n",
        "elastic_net.fit(X_train, y_train)\n",
        "\n",
        "# Feature selection: Identify features with non-zero coefficients\n",
        "selected_features = np.where(elastic_net.coef_ != 0)[0]\n",
        "print(f\"Selected features: {selected_features}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zndxRs3PujaX",
        "outputId": "2cb9ff08-5516-4624-de30-f83acf62fd25"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal alpha: 0.1\n",
            "Optimal l1_ratio: 0.1\n",
            "Selected features: [0 1 2 3 4 5 6 7 8 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. How do you pickle and unpickle a trained Elastic Net Regression model in Python?\n",
        "\n",
        "Pickling a Model:\n",
        "\n",
        "Pickling: Save the trained model to a file using pickle."
      ],
      "metadata": {
        "id": "bIqKNpx5uwRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Train the model\n",
        "elastic_net = ElasticNet(alpha=optimal_alpha, l1_ratio=optimal_l1_ratio)\n",
        "elastic_net.fit(X_train, y_train)\n",
        "\n",
        "# Save the model\n",
        "with open('elastic_net_model.pkl', 'wb') as file:\n",
        "    pickle.dump(elastic_net, file)\n"
      ],
      "metadata": {
        "id": "6DlYftOXutOg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unpickling a Model:\n",
        "\n",
        "Unpickling: Load the saved model from the file."
      ],
      "metadata": {
        "id": "kABOa_6Ru3VS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "with open('elastic_net_model.pkl', 'rb') as file:\n",
        "    loaded_model = pickle.load(file)\n",
        "\n",
        "# Use the loaded model for predictions\n",
        "predictions = loaded_model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "gQwXwo9yu02T"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9. What is the purpose of pickling a model in machine learning?\n",
        "Purpose of Pickling:\n",
        "\n",
        "Persistence: Save a trained model to a file so it can be reused without retraining.\n",
        "\n",
        "Deployment: Deploy the model in a production environment for real-time predictions.\n",
        "\n",
        "Portability: Transfer the model to different systems or environments.\n",
        "\n",
        "Versioning: Save different versions of models to track changes and improvements.\n",
        "\n",
        "Pickling allows for efficient storage and retrieval of machine learning models, facilitating model deployment and reproducibility."
      ],
      "metadata": {
        "id": "KZEQjqj-u80D"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9dTe2SXlu5QI"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}